# IMX500으로 객체인식하고 Hailo로 얼굴인식하는 통합 코드

```python
import argparse
import sys
from functools import lru_cache
from pathlib import Path

import cv2
import numpy as np
import time

from picamera2 import Picamera2
from picamera2.devices import IMX500
from picamera2.devices.imx500 import (
    NetworkIntrinsics,
    postprocess_nanodet_detection
)
from utils.face_recognizer import FaceRecognizer

last_detections = []
last_results = None


class Detection:
    def __init__(self, coords, category, conf, metadata):
        self.category = category
        self.conf = conf
        self.box = imx500.convert_inference_coords(coords, metadata, picam2)


def parse_detections(metadata: dict):
    global last_detections
    threshold = args.threshold
    iou       = args.iou
    max_det   = args.max_detections

    np_out = imx500.get_outputs(metadata, add_batch=True)
    if np_out is None:
        return last_detections

    iw, ih = imx500.get_input_size()
    if intrinsics.postprocess == "nanodet":
        boxes, scores, classes = postprocess_nanodet_detection(
            outputs=np_out[0], conf=threshold,
            iou_thres=iou, max_out_dets=max_det
        )[0]
        from picamera2.devices.imx500.postprocess import scale_boxes
        boxes = scale_boxes(boxes, 1, 1, ih, iw, False, False)
    else:
        boxes, scores, classes = np_out[0][0], np_out[1][0], np_out[2][0]
        if intrinsics.bbox_normalization:
            boxes = boxes / ih
        if intrinsics.bbox_order == "xy":
            boxes = boxes[:, [1, 0, 3, 2]]
        boxes = np.array_split(boxes, 4, axis=1)
        boxes = zip(*boxes)

    last_detections = [
        Detection(b, c, s, metadata)
        for b, s, c in zip(boxes, scores, classes)
        if s > threshold
    ]
    return last_detections


@lru_cache
def get_labels():
    labels = intrinsics.labels
    if intrinsics.ignore_dash_labels:
        labels = [l for l in labels if l and l != "-"]
    return labels


def draw_imx_detections(frame: np.ndarray, detections):
    """원본 프레임에 IMX500 Object Detection 결과를 그림."""
    labels = get_labels()
    for det in detections:
        x, y, w, h = det.box
        text = f"{labels[int(det.category)]} ({det.conf:.2f})"
        (tw, th), baseline = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)
        tx, ty = x + 5, y + 15

        overlay = frame.copy()
        cv2.rectangle(overlay, (tx, ty - th), (tx + tw, ty + baseline), (255,255,255), cv2.FILLED)
        cv2.addWeighted(overlay, 0.3, frame, 0.7, 0, frame)

        cv2.putText(frame, text, (tx, ty), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,255), 1)
        cv2.rectangle(frame, (x, y), (x + w, y + h), (0,255,0), 2)

    # ROI 그리기 (원하면)
    if intrinsics.preserve_aspect_ratio:
        bx, by, bw, bh = imx500.get_roi_scaled(last_request)
        cv2.rectangle(frame, (bx,by), (bx+bw,by+bh), (255,0,0), 1)
        cv2.putText(frame, "ROI", (bx+5, by+15), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,0,0), 1)


def draw_face_results(frame: np.ndarray, face_results):
    """원본 프레임에 얼굴 인식 결과를 별도 함수로 그림."""
    for fx, fy, fw, fh, fid in face_results:
        cv2.rectangle(frame, (fx, fy), (fx + fw, fy + fh), (255,0,255), 2)
        cv2.putText(frame, str(fid), (fx, fy - 5),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,0,255), 1)


if __name__ == "__main__":
    MODEL_DIR = "./model/"
    DB_PATH = Path("face_db.sqlite")
    # LABEL_PATH = Path("./model/labels.txt")
    LABEL_PATH = Path("/home/god/yolo-test/picamera2/examples/imx500/assets/coco_labels.txt")
    
    # 최소한의 argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("--threshold", type=float, default=0.55)
    parser.add_argument("--iou", type=float, default=0.65)
    parser.add_argument("--max-detections", type=int, default=10)
    args = parser.parse_args()

    # imx500 = IMX500(MODEL_DIR + "/best_yolo11n.rpk") # 경로
    imx500 = IMX500("/usr/share/imx500-models/imx500_network_ssd_mobilenetv2_fpnlite_320x320_pp.rpk") # 경로

    intrinsics = imx500.network_intrinsics or NetworkIntrinsics()
    intrinsics.task = "object detection"
    intrinsics.labels = [line.strip() for line in LABEL_PATH.read_text().splitlines()]

    intrinsics.update_with_defaults()

    picam2 = Picamera2(imx500.camera_num)

    cfg = picam2.create_preview_configuration(controls={"FrameRate": intrinsics.inference_rate},buffer_count=12)
    imx500.show_network_fw_progress_bar()
    picam2.start(cfg, show_preview=False)
    # cv2.namedWindow("Integrated Demo", cv2.WINDOW_NORMAL)

    # Face Part
    recognizer = FaceRecognizer(MODEL_DIR, DB_PATH)
    prev_time = time.time()

    while True:
        last_request = picam2.capture_request()
        frame        = last_request.make_array("main")
        frame        = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
        metadata     = last_request.get_metadata()
    
        detections   = parse_detections(metadata)

        # 1) 사용자 얼굴 인식 파이프라인 결과
        frame = recognizer.recognize_frame(frame)

        # 2) IMX 디텍션
        draw_imx_detections(frame, detections)
        # 현재 시간과 이전 프레임 시간 차이로 FPS 계산
        curr_time = time.time()
        fps = 1.0 / (curr_time - prev_time)
        prev_time = curr_time
        # 하단에 FPS 표시
        fps_text = f"FPS: {fps:.2f}"
        cv2.putText(frame, fps_text,
            (10, frame.shape[0] - 10),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.7,               # 폰트 크기
            (255, 255, 255),   # 흰색
            2                  # 두께
        )

        cv2.imshow("Integrated Demo", frame)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

        last_request.release()

    picam2.stop()
    cv2.destroyAllWindows()
```