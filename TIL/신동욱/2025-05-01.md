# Hailo 사용기
## AI 가속기?
> AI 칩, 딥 러닝 프로세서 또는 신경 처리 장치(NPU)라고도 하는 인공 지능(AI) 가속기는 AI 신경망, 딥 러닝 및 머신 러닝의 속도를 높이기 위해 구축된 하드웨어 가속기입니다. (출처 : IBM)

- 사실 AI 가속기는 생소한 것이 아니다

- 컴퓨터는 예로부터 "특수 작업"에 가속기를 활용해왔다

- 보조 프로세서의 대표적인 예로는 그래픽 처리 장치(GPU), 사운드 카드, 비디오 카드 등이 있다

- 지난 10년 동안 AI 애플리케이션이 성장하면서 기존의 중앙 처리 장치(CPU)와 일부 GPU는 AI 애플리케이션을 실행하는 데 필요한 대량의 데이터를 처리할 수 없게 되었다


### AI 가속기의 이점
> 속도, 효율성, 설계

#### 속도
- AI 가속기는 시스템 지연을 측정하는 단위인 지연 시간이 획기적으로 낮아 기존 CPU보다 훨씬 빠르다

- 몇 초, 심지어 몇 밀리초의 지연도 위험할 수 있는 의료 및 자율 주행 차량 분야의 AI 애플리케이션 개발에서 짧은 지연 시간은 특히 중요

#### 효율성
- AI 가속기는 다른 표준 컴퓨팅 시스템보다 100배에서 1,000배 더 효율적일 수 있다

- 데이터 센터에 사용되는 대형 AI 가속기 칩과 엣지 장치에 일반적으로 사용되는 소형 가속기 칩은 모두 기존 제품보다 전력을 덜 소모하고 발열량도 적다

#### 설계
- AI 가속기는 이기종 아키텍처라고 하는 기능을 갖추고 있어 여러 프로세서가 별도의 작업을 지원할 수 있으며, 이를 통해 컴퓨팅 성능을 AI 애플리케이션에 필요한 수준으로 향상시킬 수 있다

### AI 가속기의 기능
> 병렬 처리, AI 학습의 정밀도 감소, 메모리 계층 구조

#### 병렬 처리
- 한 번에 많은 계산을 수행할 수 있다

#### AI 학습의 정밀도 감소
- AI 가속기는 전력을 절약하기 위해 정밀도 감소 연이라는 기능을 사용할 수 있음

- 신경망은 범용 칩이 사용하는 32비트 대신 16비트 또는 8비트 부동 소수점 숫자를 사용하여 여전히 높은 성능을 발휘함

- 즉, 정확도를 유지하면서 더 낮은 에너지 소비로 더 빠른 처리 속도를 달성할 수 있음

#### 메모리 계층 구조
- AI 가속기에서 데이터가 한 곳에서 다른 곳으로 이동하는 방식은 AI 워크로드를 최적화하는 데 매우 중요

- AI 가속기는 범용 칩과는 다른 메모리 아키텍쳐를 사용하기 때문에 지연 시간을 줄이고 처리량을 향상시킬 수 있음

- 온칩 캐시 및 고대역폭 메모리를 비롯한 이러한 특수 설계 기능은 고성능 AI 워크로드에 필요한 대규모 데이터 세트의 처리 속도를 높이는 데 반드시 필요

### AI 가속기 종류
> NPU, GPU 만 하자

#### NPU
- 신경망 처리 장치(NPU)는 딥 러닝 및 신경망 고유의 데이터 처리에 특화된 AI 가속기

- NPU는 다른 칩보다 대량의 데이터를 빠르게 처리할 수 있음

- ChatGPT와 같은 인기 있는 AI 및 ML 애플리케이션의 기반이 되는 신경망 및 이미지 인식과 같은 머신 러닝과 같이 광범위한 AI 작업을 수행할 수 있음

#### GPU
- 컴퓨터 그래픽 및 이미지 처리 성능을 향상시키기 위해 만들어진 전자 회로인 GPU는 비디오 카드, 마더보드, 휴대폰 등 다양한 장치에 사용됨

- 그러나 병렬 처리 기능으로 인해 AI 모델 학습에도 점점 더 많이 사용되고 있음

- 인기 있는 한 가지 방법은 많은 GPU를 단일 AI 시스템에 연결하여 해당 시스템의 처리 능력을 높이는 것